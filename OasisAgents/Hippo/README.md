<img src="../../Rsrcs/Logo/logo.png" alt=""> 

**OpenOasis，绿洲，一个物理世界机理模型的开放实验项目。**

---------------------------------------------------------------------------------

# 海马体深度学习框架

*Hippo(short for hippocampus) model*  

基于 [PyNet](https://github.com/Kaslanarian/PyNet) 、[MatrixSlow](https://github.com/zc911/MatrixSlow)、[tinynn](https://github.com/borgwang/tinynn) 等项目实现的一套极简的深度强化学习框架，主要用于理解和测试深度学习算法。  

**组件抽象 - 深度学习部分**

首先考虑神经网络运算的流程，神经网络运算主要包含训练 training 和预测 predict （或 inference） 两个阶段，训练的基本流程是：  
```
输入数据 -> 网络层前向传播 -> 计算损失 -> 网络层反向传播梯度 -> 更新参数  
```
预测的基本流程是：
```
输入数据 -> 网络层前向传播 -> 输出结果
```

从运算的角度可以分为三种类型的计算：

1. 数据在网络层之间的流动：前向传播和反向传播可以看做是张量 Tensor（多维数组）在网络层之间的流动（前向传播流动的是输入输出，反向传播流动的是梯度），每个网络层会进行一定的运算，然后将结果输入给下一层；
2. 计算损失：衔接前向和反向传播的中间过程，定义了模型的输出与真实值之间的差异，用来后续提供反向传播所需的信息；
3. 参数更新：使用计算得到的梯度对网络参数进行更新的一类计算。

基于这个三种类型，我们可以对网络的基本组件做一个抽象：

- tensor 张量，这个是神经网络中数据的基本单位
- layer 网络层，负责接收上一层的输入，进行该层的运算，将结果输出给下一层，由于 tensor 的流动有前向和反向两个方向，因此对于每种类型网络层我们都需要同时实现 forward 和 backward 两种运算
- loss 损失，在给定模型预测值与真实值之后，该组件输出损失值以及关于最后一层的梯度（用于梯度回传）
- optimizer 优化器，负责使用梯度更新模型的参数

然后我们还需要一些组件把上面这个 4 种基本组件整合到一起，形成一个 pipeline：

- net 组件负责管理 tensor 在 layers 之间的前向和反向传播，同时能提供获取参数、设置参数、获取梯度的接口
- model 组件负责整合所有组件，形成整个 pipeline。即：
```
net 组件进行前向传播 -> losses 组件计算损失和梯度 -> net 组件将梯度反向传播 -> optimizer 组件将梯度更新到参数
```

---------------------------------------------------------------------------------

